{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:49:12.400198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 14:49:13.061461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-29 14:49:13.061516: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-29 14:49:13.061522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_frames_2(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, data.shape[1]-1, :, :]\n",
    "    return x, y\n",
    "\n",
    "#Toma todos los colores existentes en la imagen\n",
    "def get_colors(image):\n",
    "  aux = []\n",
    "  band = True\n",
    "  for i in image:\n",
    "    for j in i:\n",
    "\n",
    "      for k in aux:\n",
    "        if j.tolist() == k:\n",
    "          band = False\n",
    "          break\n",
    "      if band:\n",
    "        aux.append(j.tolist())\n",
    "      band = True\n",
    "  return np.array(aux)\n",
    "\n",
    "def balance_img_categories(img, palette, balancer):\n",
    "  #palette = np.sort(palette)\n",
    "  rows = len(img)\n",
    "  cols = len(img[0])\n",
    "  for i in range(rows):\n",
    "    for j in range(cols):\n",
    "      pos = np.where(palette == img[i,j])[0][0]\n",
    "      img[i,j] = balancer[pos]\n",
    "  return img\n",
    "\n",
    "#Función para dada una paleta solo tomar los colores de esa paleta en la imagen\n",
    "def quantizetopalette(silf, palette, dither=False, mode=\"P\"):\n",
    "  \"\"\"Convert an RGB or L mode image to use a given P image's palette.\"\"\"\n",
    "  silf.load()\n",
    "  palette.load()\n",
    "  im = silf.im.convert(mode, 0, palette.im)\n",
    "  # the 0 above means turn OFF dithering making solid colors\n",
    "  return silf._new(im)\n",
    "\n",
    "#Realiza las operaciones necesarias para obtener una imagen RGB por una paleta de colores\n",
    "def rgb_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('P', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img).convert(\"RGB\")\n",
    "  newImage = quantizetopalette(oldImage,palImage)\n",
    "  res_image = np.asarray(newImage.convert(\"RGB\"))\n",
    "  return res_image\n",
    "\n",
    "def gray_quantized(img, palette):\n",
    "  rows, cols = len(img), len(img[0])\n",
    "  total_vals = 1\n",
    "  for i in palette.shape:\n",
    "    total_vals *= i\n",
    "  palettedata = palette.reshape(total_vals).tolist()\n",
    "  palImage = Image.new('L', (rows, cols))\n",
    "  palImage.putpalette(palettedata*32)\n",
    "  oldImage = Image.fromarray(img, 'L')\n",
    "  newImage = quantizetopalette(oldImage,palImage, mode=\"L\")\n",
    "  res_image = np.asarray(newImage)\n",
    "  return res_image\n",
    "\n",
    "def recolor_greys_image(data, palette):\n",
    "    rows, cols = len(data), len(data[0])\n",
    "    aux = np.zeros((rows, cols), dtype=np.uint64)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            aux[i,j] = min(palette, key= lambda x:abs(x-data[i,j]))\n",
    "    return aux\n",
    "\n",
    "def recolor_greys_image1(data, palette):\n",
    "    # Asegurarse de que la paleta y los datos estén en el mismo tipo de datos y rango\n",
    "    palette = np.array(palette, dtype='float32')\n",
    "    data = data.astype('float32')\n",
    "    \n",
    "    # Expandir las dimensiones de los datos y la paleta para la transmisión (broadcasting)\n",
    "    data_expanded = data[:, :, np.newaxis]  # Forma ahora es (rows, cols, 1)\n",
    "    palette_expanded = palette[np.newaxis, np.newaxis, :]  # Forma ahora es (1, 1, num_colors)\n",
    "    \n",
    "    # Calcular la diferencia absoluta entre cada píxel y cada color de la paleta\n",
    "    abs_diff = np.abs(data_expanded - palette_expanded)\n",
    "    \n",
    "    # Encontrar el índice del color más cercano en la paleta para cada píxel\n",
    "    indices_of_nearest = np.argmin(abs_diff, axis=2)\n",
    "    \n",
    "    # Mapear los índices a los valores de la paleta para obtener la imagen recoloreada\n",
    "    recolored_image = palette[indices_of_nearest]\n",
    "    \n",
    "    return recolored_image\n",
    "\n",
    "def agroup_window(data, window):\n",
    "    new_data = [data[i:window+i] for i in range(len(data)-window+1)]\n",
    "    return np.array(new_data)\n",
    "\n",
    "def add_last(data, new_vals):\n",
    "    print(f\"data: {data.shape} y new_val: {new_vals.shape}\")\n",
    "    x_test_new = data[:,1:]\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(x_test_new)):\n",
    "        l.append(np.append(x_test_new[i], new_vals[i]))\n",
    "    x_test_new = np.array(l).reshape(data.shape[:])\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "def add_lastNew(data, new_val):\n",
    "    print(f\"data: {data.shape} y new_val: {new_val.shape}\")\n",
    "    x_test_new = data[:,1:,...]  # Omite el primer paso de tiempo\n",
    "    print(f\"x_test_new: {x_test_new.shape}\")\n",
    "\n",
    "    # Asumiendo que new_val es una única predicción que se debe añadir a cada paso de tiempo en x_test_new\n",
    "    new_val = new_val.squeeze(axis=0)  # Elimina la dimensión del batch, si es necesario\n",
    "\n",
    "    print(new_val.shape)\n",
    "    # Añadir new_val a cada elemento en x_test_new\n",
    "    x_test_new = np.concatenate((x_test_new, np.expand_dims(new_val, axis=1)), axis=1)\n",
    "\n",
    "    print(\"CX\", x_test_new.shape)\n",
    "    return x_test_new\n",
    "\n",
    "#Crea cubos con su propia información de tamaño h\n",
    "def get_cubes(data, h):\n",
    "    new_data = []\n",
    "    for i in range(0, len(data)-h):\n",
    "        new_data.append(data[i:i+h])\n",
    "    new_data = np.array(new_data)\n",
    "    print(new_data.shape)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n"
     ]
    }
   ],
   "source": [
    "channels = 1\n",
    "window = 10\n",
    "categories = [0, 35, 70, 119, 177, 220, 255] \n",
    "horizon = 4\n",
    "\n",
    "parte = \"EspacioLatente\"\n",
    "\n",
    "carpeta = \"\"\n",
    "\n",
    "#leer una entrada de usuario por consola para variable de carpeta\n",
    "carpeta = input(\"Ingrese el nombre de la carpeta: \")\n",
    "print(carpeta)\n",
    "\n",
    "#crear carpeta si no existe\n",
    "if not os.path.exists(\"Resultados/ModelosConvLSTM/\"+carpeta):\n",
    "    os.makedirs(\"Resultados/ModelosConvLSTM/\"+carpeta)\n",
    "\n",
    "imagenInicial = 300\n",
    "\n",
    "x = np.load(\"Resultados/NpyEspacioLatente/V1/Dataset120x360Encoded.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:49:17.434403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.434790: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.439643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.439931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.440332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.440579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.441859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 14:49:17.582755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.583049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.583436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.583667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.584089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:17.584388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.287093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.287403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.287798: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.288104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.288515: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.288727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 135 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-02-29 14:49:18.288945: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-29 14:49:18.289297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9293 MB memory:  -> device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "2024-02-29 14:49:18.303006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 135.56M (142147584 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-29 14:49:18.303470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 122.01M (127932928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-02-29 14:49:18.303908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:735] failed to allocate 109.81M (115139840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 60\n",
      "cols 180\n",
      "Parte EspacioLatente\n",
      "x (1254, 60, 180, 1)\n",
      "x float32\n",
      "x 0.19354352\n",
      "x 0.9002678\n",
      "(1245, 10, 60, 180, 1)\n",
      "Forma de datos de entrenamiento: (696, 10, 60, 180, 1)\n",
      "Forma de datos de validación: (175, 10, 60, 180, 1)\n",
      "Forma de datos de pruebas: (374, 10, 60, 180, 1)\n",
      "Training dataset shapes: (696, 9, 60, 180, 1), (696, 60, 180, 1)\n",
      "Validation dataset shapes: (175, 9, 60, 180, 1), (175, 60, 180, 1)\n",
      "Test dataset shapes: (374, 9, 60, 180, 1), (374, 60, 180, 1)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 60, 180, 1  0         \n",
      "                             )]                                  \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, None, 60, 180, 16  27264     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 60, 180, 16  64       \n",
      " ormalization)               )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, None, 60, 180, 16  51264     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 60, 180, 16  64       \n",
      " hNormalization)             )                                   \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 60, 180, 16)       18496     \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 60, 180, 1)        145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97,297\n",
      "Trainable params: 97,233\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 14:49:32.208230: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 258.07MiB (rounded to 270604800)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-02-29 14:49:32.208315: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2024-02-29 14:49:32.208349: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 30, Chunks in use: 30. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 1.3KiB client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208374: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 2, Chunks in use: 1. 1.5KiB allocated for chunks. 768B in use in bin. 576B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208397: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208418: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208442: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 2, Chunks in use: 1. 11.2KiB allocated for chunks. 6.2KiB in use in bin. 6.2KiB client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208462: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208481: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208505: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 2, Chunks in use: 2. 72.0KiB allocated for chunks. 72.0KiB in use in bin. 72.0KiB client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208529: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 4, Chunks in use: 3. 364.0KiB allocated for chunks. 300.0KiB in use in bin. 300.0KiB client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208549: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208568: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208587: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208606: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208625: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208644: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208664: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208683: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208702: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208724: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 0. 98.38MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208743: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208768: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-29 14:49:32.208792: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 258.07MiB was 256.00MiB, Chunk State: \n",
      "2024-02-29 14:49:32.208809: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 103625984\n",
      "2024-02-29 14:49:32.208833: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000000 of size 256 next 1\n",
      "2024-02-29 14:49:32.208850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000100 of size 1280 next 2\n",
      "2024-02-29 14:49:32.208866: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000600 of size 256 next 3\n",
      "2024-02-29 14:49:32.208881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000700 of size 256 next 4\n",
      "2024-02-29 14:49:32.208896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000800 of size 256 next 6\n",
      "2024-02-29 14:49:32.208911: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000900 of size 256 next 7\n",
      "2024-02-29 14:49:32.208926: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000a00 of size 256 next 8\n",
      "2024-02-29 14:49:32.208941: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000b00 of size 256 next 5\n",
      "2024-02-29 14:49:32.208956: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000c00 of size 256 next 13\n",
      "2024-02-29 14:49:32.208971: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000d00 of size 256 next 15\n",
      "2024-02-29 14:49:32.208986: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000e00 of size 256 next 12\n",
      "2024-02-29 14:49:32.209002: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934000f00 of size 256 next 14\n",
      "2024-02-29 14:49:32.209017: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001000 of size 256 next 16\n",
      "2024-02-29 14:49:32.209032: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001100 of size 256 next 17\n",
      "2024-02-29 14:49:32.209047: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001200 of size 256 next 18\n",
      "2024-02-29 14:49:32.209062: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001300 of size 256 next 19\n",
      "2024-02-29 14:49:32.209077: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001400 of size 256 next 21\n",
      "2024-02-29 14:49:32.209092: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001500 of size 256 next 24\n",
      "2024-02-29 14:49:32.209107: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001600 of size 256 next 26\n",
      "2024-02-29 14:49:32.209122: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001700 of size 256 next 25\n",
      "2024-02-29 14:49:32.209137: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001800 of size 256 next 27\n",
      "2024-02-29 14:49:32.209152: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001900 of size 256 next 28\n",
      "2024-02-29 14:49:32.209167: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001a00 of size 256 next 29\n",
      "2024-02-29 14:49:32.209182: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001b00 of size 256 next 31\n",
      "2024-02-29 14:49:32.209197: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001c00 of size 256 next 33\n",
      "2024-02-29 14:49:32.209212: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001d00 of size 256 next 34\n",
      "2024-02-29 14:49:32.209227: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001e00 of size 256 next 35\n",
      "2024-02-29 14:49:32.209242: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934001f00 of size 256 next 36\n",
      "2024-02-29 14:49:32.209257: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934002000 of size 256 next 37\n",
      "2024-02-29 14:49:32.209275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934002100 of size 256 next 40\n",
      "2024-02-29 14:49:32.209291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934002200 of size 256 next 41\n",
      "2024-02-29 14:49:32.209306: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe934002300 of size 768 next 38\n",
      "2024-02-29 14:49:32.209322: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934002600 of size 768 next 39\n",
      "2024-02-29 14:49:32.209339: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe934002900 of size 5120 next 9\n",
      "2024-02-29 14:49:32.209355: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934003d00 of size 6400 next 10\n",
      "2024-02-29 14:49:32.209372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934005600 of size 102400 next 11\n",
      "2024-02-29 14:49:32.209388: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe93401e600 of size 102400 next 20\n",
      "2024-02-29 14:49:32.209403: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934037600 of size 36864 next 30\n",
      "2024-02-29 14:49:32.209419: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe934040600 of size 65536 next 23\n",
      "2024-02-29 14:49:32.209435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934050600 of size 102400 next 22\n",
      "2024-02-29 14:49:32.209450: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fe934069600 of size 36864 next 32\n",
      "2024-02-29 14:49:32.209466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fe934072600 of size 103157504 next 18446744073709551615\n",
      "2024-02-29 14:49:32.209482: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2024-02-29 14:49:32.209503: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 30 Chunks of size 256 totalling 7.5KiB\n",
      "2024-02-29 14:49:32.209522: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 768 totalling 768B\n",
      "2024-02-29 14:49:32.209540: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-02-29 14:49:32.209559: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6400 totalling 6.2KiB\n",
      "2024-02-29 14:49:32.209578: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 36864 totalling 72.0KiB\n",
      "2024-02-29 14:49:32.209597: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 102400 totalling 300.0KiB\n",
      "2024-02-29 14:49:32.209616: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 387.8KiB\n",
      "2024-02-29 14:49:32.209634: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 103625984 memory_limit_: 142147584 available bytes: 38521600 curr_region_allocation_bytes_: 284295168\n",
      "2024-02-29 14:49:32.209659: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                       142147584\n",
      "InUse:                          397056\n",
      "MaxInUse:                       540160\n",
      "NumAllocs:                          97\n",
      "MaxAllocSize:                   102400\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-02-29 14:49:32.209686: W tensorflow/tsl/framework/bfc_allocator.cc:492] *___________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "\n",
    "    rows = x.shape[1]\n",
    "    cols = x.shape[2]\n",
    "    print(\"rows\",rows)\n",
    "    print(\"cols\",cols)    \n",
    "    \n",
    "    print(\"Parte\", parte)\n",
    "    print(\"x\", x.shape)\n",
    "    print(\"x\", x.dtype)\n",
    "    print(\"x\", x.min())\n",
    "    print(\"x\", x.max())\n",
    "\n",
    "    x_2 = agroup_window(x, window)\n",
    "    print(x_2.shape)\n",
    "    x_train = x_2[:int(len(x_2)*.7)]\n",
    "    x_test = x_2[int(len(x_2)*.7):]\n",
    "    x_validation = x_train[int(len(x_train)*.8):]\n",
    "    x_train = x_train[:int(len(x_train)*.8)]\n",
    "\n",
    "    x_train = x_train.reshape(len(x_train), window, rows, cols, channels)\n",
    "    x_validation = x_validation.reshape(len(x_validation), window, rows, cols, channels)\n",
    "    x_test = x_test.reshape(len(x_test), window, rows, cols, channels)\n",
    "\n",
    "    print(\"Forma de datos de entrenamiento: {}\".format(x_train.shape))\n",
    "    print(\"Forma de datos de validación: {}\".format(x_validation.shape))\n",
    "    print(\"Forma de datos de pruebas: {}\".format(x_test.shape))\n",
    "\n",
    "    x_train, y_train = create_shifted_frames_2(x_train)\n",
    "    x_validation, y_validation = create_shifted_frames_2(x_validation)\n",
    "    x_test, y_test = create_shifted_frames_2(x_test)\n",
    "\n",
    "    print(\"Training dataset shapes: {}, {}\".format(x_train.shape, y_train.shape))\n",
    "    print(\"Validation dataset shapes: {}, {}\".format(x_validation.shape, y_validation.shape))\n",
    "    print(\"Test dataset shapes: {}, {}\".format(x_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_test_mask.npy\", x_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_test_mask.npy\", y_test)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_train_mask.npy\", x_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_train_mask.npy\", y_train)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/x_validation_mask.npy\", x_validation)\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/y_validation_mask.npy\", y_validation)\n",
    "\n",
    "    # Define the path where you want to save the log file\n",
    "    log_file_path = \"Resultados/ModelosConvLSTM/\"+carpeta+\"/InfoConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".txt\"\n",
    "\n",
    "    # Save the original stdout so we can restore it later\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    #Construction of Convolutional LSTM network\n",
    "    inp = keras.layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "    #It will be constructed a 3 ConvLSTM2D layers with batch normalization,\n",
    "    #Followed by a Conv3D layer for the spatiotemporal outputs.\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(inp)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (5,5), padding= \"same\", return_sequences= True, activation= \"relu\")(m)\n",
    "    m = keras.layers.BatchNormalization()(m)\n",
    "    m = keras.layers.ConvLSTM2D(16, (3,3), padding= \"same\", activation= \"relu\")(m)\n",
    "    m = keras.layers.Conv2D(channels, (3,3), activation= \"sigmoid\", padding= \"same\")(m)\n",
    "    model = keras.models.Model(inp, m)\n",
    "    model.compile(loss= \"binary_crossentropy\", optimizer= \"Adam\")\n",
    "    print(model.summary())\n",
    "    #Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor= \"val_loss\", patience= 6, restore_best_weights= True)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor= \"val_loss\", patience= 6)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath= \"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\",\n",
    "        monitor= \"val_loss\",\n",
    "        save_best_only= True,\n",
    "        mode= \"min\"\n",
    "    )\n",
    "    # Model training with logs redirected to a file\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        sys.stdout = log_file  # Redirect stdout to the log file\n",
    "        model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=2,\n",
    "            epochs=30,\n",
    "            validation_data=(x_validation, y_validation),\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "        sys.stdout = original_stdout  # Restore stdout back to normal\n",
    "\n",
    "    print(f\"Training log was saved to {log_file_path}\")\n",
    "\n",
    "    #Guardar el modelo\n",
    "    \n",
    "    model.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/ConvLSTM2D_Mask\"+str(rows)+\"_\"+str(cols)+\".h5\")\n",
    "\n",
    "    print(imagenInicial)\n",
    "\n",
    "    example = x_test[imagenInicial]\n",
    "\n",
    "    print(example.shape)\n",
    "\n",
    "    err = model.evaluate(x_test, y_test, batch_size= 2)\n",
    "    print(\"El error del modelo es: {}\".format(err))\n",
    "    preds = model.predict(x_test, batch_size= 2)\n",
    "    print(\"preds\",preds.shape)\n",
    "    x_test_new = add_last(x_test, preds[:])\n",
    "    preds2 = model.predict(x_test_new, batch_size= 2)\n",
    "    print(\"preds2\",preds2.shape)\n",
    "    x_test_new = add_last(x_test_new, preds2[:])\n",
    "    preds3 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds3\",preds3.shape)\n",
    "    x_test_new = add_last(x_test_new, preds3[:])\n",
    "    preds4 = model.predict(x_test_new, batch_size= 2)\n",
    "    print (\"preds4\",preds4.shape)\n",
    "    res_forecast = add_last(x_test_new, preds4[:])\n",
    "    print(\"PREDSS\",res_forecast.shape)\n",
    "\n",
    "    np.save(\"Resultados/ModelosConvLSTM/\"+carpeta+\"/PredictionsConvolutionLSTM_forecast_\"+str(rows)+\"_\"+str(cols)+\"_\"+parte+\"_w\"+str(window)+\".npy\", res_forecast)  #Guardar el vector de predicciones\n",
    "\n",
    "    print(\"Res_forecast\" , res_forecast.shape)\n",
    "\n",
    "    print(\"x_test\" , x_test.shape)\n",
    "    print(\"x_test_new\" , x_test_new.shape)\n",
    "    print(\"y_test\" , y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropImage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
